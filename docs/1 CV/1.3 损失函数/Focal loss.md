![img](assets/Focal%20loss/1055519-20180818170840882-453549240.png)

这个损失函数是在标准交叉熵损失基础上修改得到的。这个函数可以通过减少易分类样本的权重，使得模型在训练时更专注于难分类的样本。为了证明focal loss的有效性，作者设计了一个dense detector：RetinaNet，并且在训练时采用focal loss训练。

首先回顾二分类交叉熵损失：

![img](assets/Focal%20loss/1055519-20180818162755861-24998254.png)

其中 y 是真实样本的标签（1正0负）， y’ 是经过 sigmoid 激活函数的预测输出（数值在0-1之间）。可见普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢且可能无法优化至最优。

作者由此提出Focal loss函数：

![img](assets/Focal%20loss/1055519-20180818174822290-765890427.png)

首先在原有的基础上加了一个因子，其中Gamma>0使得减少易分类样本的损失，使得模型更关注于困难的、错分的样本。

例如：Gamma为2时，对于正类样本而言，预测结果为0.95肯定是简单样本，所以（1-0.95）的gamma次方就会很小，这时损失函数值就变得更小。而预测概率为0.3的样本其损失相对很大。对于负类样本而言同样，预测0.1的结果应当远比预测0.7的样本损失值要小得多。对于预测概率为0.5时，损失只减少了0.25倍。所以更加关注于这种难以区分的样本。这样减少了简单样本的影响，大量预测概率很小的样本叠加起来后的效应才可能比较有效。

在此基础上，再引入一个平衡因子 Alpha，用来平衡正负样本本身的数量比例不均（即类别不均衡）：

![img](assets/Focal%20loss/1055519-20180818174944824-933422059.png)

只添加Alpha虽然可以平衡正负样本的重要性，但是无法解决简单与困难样本的问题，因此针对难分样本的Gamma也必不可少。

这里的两个参数α和γ协调来控制，本文作者采用α=0.25，γ=2效果最好。

Gamma调节简单样本权重降低的速率，当Gamma为0时即为交叉熵损失函数，当Gamma增加时，调整因子的影响也在增加。
