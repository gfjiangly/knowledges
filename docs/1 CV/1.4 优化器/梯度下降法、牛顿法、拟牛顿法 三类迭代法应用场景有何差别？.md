![preview](assets/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E3%80%81%E7%89%9B%E9%A1%BF%E6%B3%95%E3%80%81%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95%20%E4%B8%89%E7%B1%BB%E8%BF%AD%E4%BB%A3%E6%B3%95%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E6%9C%89%E4%BD%95%E5%B7%AE%E5%88%AB%EF%BC%9F/v2-606c8b225645e8c2bf5300985ed2f9d2_r.jpg)



## 为什么深度学习不采用牛顿法或拟牛顿法作为优化算法？

1. 牛顿法需要用到梯度和Hessian矩阵，这两个都难以求解。因为很难写出深度神经网络拟合函数的表达式，遑论直接得到其梯度表达式，更不要说得到基于梯度的Hessian矩阵了。
2. 即使可以得到梯度和Hessian矩阵，当输入向量的维度N较大时，Hessian矩阵的大小是N×N，所需要的内存非常大。
3. 在高维非凸优化问题中，鞍点相对于局部最小值的数量非常多，而且鞍点处的损失值相对于局部最小值处也比较大。而二阶优化算法是寻找梯度为0的点，所以很容易陷入鞍点。

参考：

1. https://blog.csdn.net/u011094454/article/details/79256147
2. https://www.zhihu.com/question/306051582