## 无锁编程概念

大多数人对于无所编程的理解都停留在“不用锁来写多线程程序”。毋庸置疑，这样的定义是没有问题的，但是并不完整。对于无锁编程，被学术界认可的定义更加宽泛，学术界认为，“无锁(lockfree)”实际上是代码的一种性质，而非形式。

如果程序的一部分满足接下来提到的这些条件，那么我们就可以认为他是“无锁”的，反之，如果不满足，则程序不是“无锁”的。

![img](assets/%E6%97%A0%E9%94%81%E7%BC%96%E7%A8%8B/its-lock-free.png)

通过上图，我们发现“无锁(lock-free)”这个词中的“锁(lock)”并不是指代码中的“锁(mutex)”，而是指的是能够通过某种方式“阻塞(locking up)”整个程序的可能性。这个可能性可能来源于经典的“死锁(deadlock)”，也可能由于很糟糕的内存调度顺序使得程序停滞不前（这可能变成一些恶意攻击者的突破口）。由于持有锁(mutex)的线程的调用顺序是任意的，因此最坏的情况是可能发生的，纵使有些时候，理论计算告诉我们“最坏情况”是一个不可能事件（概率为0），但是从概念上来说，只要“可能发生”阻塞，那么这个程序就不是无锁的。

举一个例子，对于下面的无锁程序，在初始 X=0 的情况下，什么样的调度顺序可以导致程序永远按无法退出循环？

```cpp
// A线程读0写1，B线程读1写0，可能一直无法退出循环
while (X == 0)
{
    X = 1 - X;
}
```

假设有两个线程A和B，A先将X值修改成1，B读到是A改后的1，然后B执行`X = 1 - X;`，X值被修改为0并写回，此时A读取X用于循环判断，读到0，不退出循环，继续修改X；B每次读到1写入0，也不退出循环，这样两个线程均永远无法退出循环。

没有人指望一个很大的工程是完全无锁的，通常来说，我们希望这个工程中某一个访问了公有内存的代码片段是无锁的。举一个例子，我们可能希望拥有一个“无锁队列”，这个无锁队列支持若干无锁的操作，诸如 push ， pop ， isEmpty 等等操作。

## “比较并交换”循环

最常讨论的RMW操作是 [比较并交换(compare-and-swap)](http://en.wikipedia.org/wiki/Compare-and-swap) (CAS)。在Win32里面，CAS通过一系列intrinsics函数实现的，比如 _InterlockedCompareExchange 。通常情况下，我们在循环中使用CAS操作来尝试提交一些操作。具体来说，我们首先拷贝一些公有变量（全局数据区）到局部变量（线程独有的栈中）中，并进行一些操作来改动局部变量的值，最后，将这些改动借助CAS操作提交至公有可见。

```cpp
void LockFreeQueue::push(Node* newHead)
{
    for (;;)
    {
        // Copy a shared variable (m_Head) to a local.
        Node* oldHead = m_Head;
 
        // Do some speculative work, not yet visible to other threads.
        newHead->next = oldHead;
 
        // Next, attempt to publish our changes to the shared variable.
        // If the shared variable hasn't changed, the CAS succeeds and we return.
        // Otherwise, repeat.
        if (_InterlockedCompareExchange(&m_Head, newHead, oldHead) == oldHead)
            return;
    }
}
```

这样的循环是无锁的，因为如果一个线程的if条件测试为false，这意味着他一定紧接着另一个线程执行完毕相同操作的线程之后。尽管在一些架构下，存在[ 弱化的CAS操作](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2748.html)，在这些CAS操作中，上述不一定是if语句判断false的充要条件，但是这些弱化的CAS操作仍然能够有效避免ABA问题。

## 顺序一致性

顺序一致性(Sequential Consistency)意味着所有的线程都有共同的对于内存访问操作的顺序的判定。这个判定的内存访问操作的顺序恰好等同于在源代码中的内存访问定义的顺序。

```cpp
int X = 0;
int Y = 0;
int r1, r2;

void thread1()
{
    int x = 1;
    X = x;
    r1 = Y;  // 编译器可能将这条语句优化到上一条语句之前
}

void thread2()
{
    int y = 1;
    Y = y;
    r2 = X;
}
```

可能会产生`r1 = r2 = 0`，这样不符合直觉的结果。

一个非常简单（但是显然不可能在实际中使用的）解决内存一致性的方式是禁用编译器优化，并且强制所有的线程在同一个处理器上面运行。

一些编程语言即使在优化了代码之后，在多核环境中，依然保证了顺序移植性。在C++11中，你可以定义拥有默认内存顺序(memory ordering)的公共的原子数据类型来实现内存访问的移植性。在Java中，你可以将公有变量标记为 volatile 已实现顺序移植性。下面是一个例子：

```cpp
std::atomic<int> X(0), Y(0);
int r1, r2;

void thread1()
{
    X.store(1);
    r1 = Y.load();
}

void thread2()
{
    Y.store(1);
    r2 = X.load();
}
```

由于C++原子操作保证了顺序一致性，因此结果`r1 = r2 = 0`是不会发生的。从编译器层面来看，编译器添加了一些额外的指令（如内存屏障或RMW操作）来保证顺序一致性。这些额外的指令带来了更大的时间花销，但是让程序员能够以最直观的方式操作内存顺序。

