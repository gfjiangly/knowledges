不要通过设置这些层学习率为0达到不训练的目的，这增加了反向时间。

应设置这些参数不需要梯度，并且不要把这部分参数传给优化器。

```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)

        for p in self.parameters():
            p.requires_grad=False

        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
```

```python
count = 0
para_optim = []
for k in model.children():   # model.modules():
    count += 1
    # 6 should be changed properly
    if count > 6:
        for param in k.parameters():
            para_optim.append(param)
    else:
        for param in k.parameters():
            param.requires_grad = False
optimizer = optim.RMSprop(para_optim, lr)

################
# another way

for idx,m in enumerate(model.modules()):
    if idx >50:
        for param in m.parameters():
            param.requires_grad = True
        else:
            for param in m.parameters():
                param.requires_grad = False
```



参考：

- https://www.jianshu.com/p/d67d62982a24